{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba5950e9",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaedfe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67eb0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c675e4",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2df30655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>ax1</th>\n",
       "      <th>ay1</th>\n",
       "      <th>az1</th>\n",
       "      <th>abs_a</th>\n",
       "      <th>gx1</th>\n",
       "      <th>gy1</th>\n",
       "      <th>gz1</th>\n",
       "      <th>abs_g</th>\n",
       "      <th>mx1</th>\n",
       "      <th>my1</th>\n",
       "      <th>mz1</th>\n",
       "      <th>abs_m</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.087654</td>\n",
       "      <td>-0.47289</td>\n",
       "      <td>1.7963</td>\n",
       "      <td>10.0840</td>\n",
       "      <td>10.2540</td>\n",
       "      <td>-0.35062</td>\n",
       "      <td>-0.28198</td>\n",
       "      <td>0.12647</td>\n",
       "      <td>0.46738</td>\n",
       "      <td>-20.869</td>\n",
       "      <td>-20.116</td>\n",
       "      <td>-47.046</td>\n",
       "      <td>55.259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097656</td>\n",
       "      <td>-0.52548</td>\n",
       "      <td>1.8822</td>\n",
       "      <td>9.9713</td>\n",
       "      <td>10.1610</td>\n",
       "      <td>-0.39804</td>\n",
       "      <td>-0.31734</td>\n",
       "      <td>0.14217</td>\n",
       "      <td>0.52854</td>\n",
       "      <td>-20.869</td>\n",
       "      <td>-20.116</td>\n",
       "      <td>-47.046</td>\n",
       "      <td>55.259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.107660</td>\n",
       "      <td>-0.62116</td>\n",
       "      <td>2.0614</td>\n",
       "      <td>9.8431</td>\n",
       "      <td>10.0760</td>\n",
       "      <td>-0.40771</td>\n",
       "      <td>-0.32397</td>\n",
       "      <td>0.17652</td>\n",
       "      <td>0.54986</td>\n",
       "      <td>-21.036</td>\n",
       "      <td>-19.948</td>\n",
       "      <td>-47.162</td>\n",
       "      <td>55.360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117660</td>\n",
       "      <td>-0.72359</td>\n",
       "      <td>2.2418</td>\n",
       "      <td>9.6954</td>\n",
       "      <td>9.9775</td>\n",
       "      <td>-0.39612</td>\n",
       "      <td>-0.32122</td>\n",
       "      <td>0.20588</td>\n",
       "      <td>0.54998</td>\n",
       "      <td>-21.036</td>\n",
       "      <td>-19.948</td>\n",
       "      <td>-47.162</td>\n",
       "      <td>55.360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.127660</td>\n",
       "      <td>-0.80609</td>\n",
       "      <td>2.3568</td>\n",
       "      <td>9.5119</td>\n",
       "      <td>9.8326</td>\n",
       "      <td>-0.35189</td>\n",
       "      <td>-0.33104</td>\n",
       "      <td>0.22139</td>\n",
       "      <td>0.53143</td>\n",
       "      <td>-21.624</td>\n",
       "      <td>-19.618</td>\n",
       "      <td>-47.125</td>\n",
       "      <td>55.437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time      ax1     ay1      az1    abs_a      gx1      gy1      gz1  \\\n",
       "0  0.087654 -0.47289  1.7963  10.0840  10.2540 -0.35062 -0.28198  0.12647   \n",
       "1  0.097656 -0.52548  1.8822   9.9713  10.1610 -0.39804 -0.31734  0.14217   \n",
       "2  0.107660 -0.62116  2.0614   9.8431  10.0760 -0.40771 -0.32397  0.17652   \n",
       "3  0.117660 -0.72359  2.2418   9.6954   9.9775 -0.39612 -0.32122  0.20588   \n",
       "4  0.127660 -0.80609  2.3568   9.5119   9.8326 -0.35189 -0.33104  0.22139   \n",
       "\n",
       "     abs_g     mx1     my1     mz1   abs_m    x         y    z  \n",
       "0  0.46738 -20.869 -20.116 -47.046  55.259  0.0  0.008333  0.0  \n",
       "1  0.52854 -20.869 -20.116 -47.046  55.259  0.0  0.016667  0.0  \n",
       "2  0.54986 -21.036 -19.948 -47.162  55.360  0.0  0.025000  0.0  \n",
       "3  0.54998 -21.036 -19.948 -47.162  55.360  0.0  0.033333  0.0  \n",
       "4  0.53143 -21.624 -19.618 -47.125  55.437  0.0  0.041667  0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data view\n",
    "df = pd.read_csv(\"human_motion_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cfe1f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1674 entries, 0 to 1673\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    1674 non-null   float64\n",
      " 1   ax1     1674 non-null   float64\n",
      " 2   ay1     1674 non-null   float64\n",
      " 3   az1     1674 non-null   float64\n",
      " 4   abs_a   1674 non-null   float64\n",
      " 5   gx1     1674 non-null   float64\n",
      " 6   gy1     1674 non-null   float64\n",
      " 7   gz1     1674 non-null   float64\n",
      " 8   abs_g   1674 non-null   float64\n",
      " 9   mx1     1674 non-null   float64\n",
      " 10  my1     1674 non-null   float64\n",
      " 11  mz1     1674 non-null   float64\n",
      " 12  abs_m   1674 non-null   float64\n",
      " 13  x       1674 non-null   float64\n",
      " 14  y       1674 non-null   float64\n",
      " 15  z       1674 non-null   float64\n",
      "dtypes: float64(16)\n",
      "memory usage: 209.4 KB\n"
     ]
    }
   ],
   "source": [
    "# Data information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d399d8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>ax1</th>\n",
       "      <th>ay1</th>\n",
       "      <th>az1</th>\n",
       "      <th>abs_a</th>\n",
       "      <th>gx1</th>\n",
       "      <th>gy1</th>\n",
       "      <th>gz1</th>\n",
       "      <th>abs_g</th>\n",
       "      <th>mx1</th>\n",
       "      <th>my1</th>\n",
       "      <th>mz1</th>\n",
       "      <th>abs_m</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1674.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.454579</td>\n",
       "      <td>-0.766946</td>\n",
       "      <td>1.827614</td>\n",
       "      <td>9.832632</td>\n",
       "      <td>10.115295</td>\n",
       "      <td>0.055683</td>\n",
       "      <td>-0.004969</td>\n",
       "      <td>0.013263</td>\n",
       "      <td>0.916464</td>\n",
       "      <td>-10.691966</td>\n",
       "      <td>-17.109228</td>\n",
       "      <td>-41.943379</td>\n",
       "      <td>49.164023</td>\n",
       "      <td>0.627240</td>\n",
       "      <td>5.266129</td>\n",
       "      <td>1.432945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.834952</td>\n",
       "      <td>0.877641</td>\n",
       "      <td>0.918574</td>\n",
       "      <td>1.920719</td>\n",
       "      <td>1.895256</td>\n",
       "      <td>0.539090</td>\n",
       "      <td>0.532700</td>\n",
       "      <td>0.744274</td>\n",
       "      <td>0.539656</td>\n",
       "      <td>9.601032</td>\n",
       "      <td>11.982089</td>\n",
       "      <td>5.966896</td>\n",
       "      <td>4.516134</td>\n",
       "      <td>0.676831</td>\n",
       "      <td>3.142047</td>\n",
       "      <td>0.975777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.087654</td>\n",
       "      <td>-5.340000</td>\n",
       "      <td>-0.860370</td>\n",
       "      <td>6.030700</td>\n",
       "      <td>6.465800</td>\n",
       "      <td>-1.454100</td>\n",
       "      <td>-2.071400</td>\n",
       "      <td>-2.344700</td>\n",
       "      <td>0.054885</td>\n",
       "      <td>-28.332000</td>\n",
       "      <td>-35.794000</td>\n",
       "      <td>-61.399000</td>\n",
       "      <td>42.357000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.271100</td>\n",
       "      <td>-1.294600</td>\n",
       "      <td>1.150875</td>\n",
       "      <td>8.265725</td>\n",
       "      <td>8.558275</td>\n",
       "      <td>-0.277435</td>\n",
       "      <td>-0.314733</td>\n",
       "      <td>-0.333460</td>\n",
       "      <td>0.514660</td>\n",
       "      <td>-18.150750</td>\n",
       "      <td>-25.475000</td>\n",
       "      <td>-45.553500</td>\n",
       "      <td>46.434250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.447187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.454600</td>\n",
       "      <td>-0.700590</td>\n",
       "      <td>1.807450</td>\n",
       "      <td>9.642600</td>\n",
       "      <td>9.962350</td>\n",
       "      <td>0.054882</td>\n",
       "      <td>0.014062</td>\n",
       "      <td>-0.010014</td>\n",
       "      <td>0.805770</td>\n",
       "      <td>-9.684500</td>\n",
       "      <td>-20.136000</td>\n",
       "      <td>-42.402000</td>\n",
       "      <td>49.011000</td>\n",
       "      <td>0.236250</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>1.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.638500</td>\n",
       "      <td>-0.201750</td>\n",
       "      <td>2.506100</td>\n",
       "      <td>11.045500</td>\n",
       "      <td>11.263500</td>\n",
       "      <td>0.399858</td>\n",
       "      <td>0.308962</td>\n",
       "      <td>0.436688</td>\n",
       "      <td>1.251350</td>\n",
       "      <td>-4.451700</td>\n",
       "      <td>-15.724000</td>\n",
       "      <td>-37.669000</td>\n",
       "      <td>51.770750</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>7.146900</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16.822000</td>\n",
       "      <td>1.304100</td>\n",
       "      <td>4.143100</td>\n",
       "      <td>15.757000</td>\n",
       "      <td>16.036000</td>\n",
       "      <td>1.718600</td>\n",
       "      <td>1.785100</td>\n",
       "      <td>2.719200</td>\n",
       "      <td>3.226600</td>\n",
       "      <td>10.688000</td>\n",
       "      <td>13.475000</td>\n",
       "      <td>-29.756000</td>\n",
       "      <td>69.531000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Time          ax1          ay1          az1        abs_a  \\\n",
       "count  1674.000000  1674.000000  1674.000000  1674.000000  1674.000000   \n",
       "mean      8.454579    -0.766946     1.827614     9.832632    10.115295   \n",
       "std       4.834952     0.877641     0.918574     1.920719     1.895256   \n",
       "min       0.087654    -5.340000    -0.860370     6.030700     6.465800   \n",
       "25%       4.271100    -1.294600     1.150875     8.265725     8.558275   \n",
       "50%       8.454600    -0.700590     1.807450     9.642600     9.962350   \n",
       "75%      12.638500    -0.201750     2.506100    11.045500    11.263500   \n",
       "max      16.822000     1.304100     4.143100    15.757000    16.036000   \n",
       "\n",
       "               gx1          gy1          gz1        abs_g          mx1  \\\n",
       "count  1674.000000  1674.000000  1674.000000  1674.000000  1674.000000   \n",
       "mean      0.055683    -0.004969     0.013263     0.916464   -10.691966   \n",
       "std       0.539090     0.532700     0.744274     0.539656     9.601032   \n",
       "min      -1.454100    -2.071400    -2.344700     0.054885   -28.332000   \n",
       "25%      -0.277435    -0.314733    -0.333460     0.514660   -18.150750   \n",
       "50%       0.054882     0.014062    -0.010014     0.805770    -9.684500   \n",
       "75%       0.399858     0.308962     0.436688     1.251350    -4.451700   \n",
       "max       1.718600     1.785100     2.719200     3.226600    10.688000   \n",
       "\n",
       "               my1          mz1        abs_m            x            y  \\\n",
       "count  1674.000000  1674.000000  1674.000000  1674.000000  1674.000000   \n",
       "mean    -17.109228   -41.943379    49.164023     0.627240     5.266129   \n",
       "std      11.982089     5.966896     4.516134     0.676831     3.142047   \n",
       "min     -35.794000   -61.399000    42.357000     0.000000     0.008333   \n",
       "25%     -25.475000   -45.553500    46.434250     0.000000     2.500000   \n",
       "50%     -20.136000   -42.402000    49.011000     0.236250     5.200000   \n",
       "75%     -15.724000   -37.669000    51.770750     1.500000     7.146900   \n",
       "max      13.475000   -29.756000    69.531000     1.500000    12.000000   \n",
       "\n",
       "                 z  \n",
       "count  1674.000000  \n",
       "mean      1.432945  \n",
       "std       0.975777  \n",
       "min       0.000000  \n",
       "25%       0.447187  \n",
       "50%       1.593750  \n",
       "75%       2.500000  \n",
       "max       2.500000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621e63f6",
   "metadata": {},
   "source": [
    "### Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e81064da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = df[df.columns.drop([\"Time\", \"abs_a\", \"abs_g\", \"abs_m\", \"x\", \"y\", \"z\"])]\n",
    "\n",
    "# Target\n",
    "y = df[[\"x\", \"y\", \"z\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669004c9",
   "metadata": {},
   "source": [
    "### Training, Validation and Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e023304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set & Testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 786)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84b3176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set & Validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                  y_train,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  random_state = 786)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0fb8521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns to predict x, y and z\n",
    "X_train_x = X_train[[\"ax1\", \"gx1\", \"mx1\"]]\n",
    "X_val_x = X_val[[\"ax1\", \"gx1\", \"mx1\"]]\n",
    "X_test_x = X_test[[\"ax1\", \"gx1\", \"mx1\"]]\n",
    "y_train_x = y_train[\"x\"]\n",
    "y_test_x = y_test[\"x\"]\n",
    "y_val_x = y_val[\"x\"]\n",
    "\n",
    "X_train_y = X_train[[\"ay1\", \"gy1\", \"my1\"]]\n",
    "X_val_y = X_val[[\"ay1\", \"gy1\", \"my1\"]]\n",
    "X_test_y = X_test[[\"ay1\", \"gy1\", \"my1\"]]\n",
    "y_train_y = y_train[\"y\"]\n",
    "y_test_y = y_test[\"y\"]\n",
    "y_val_y = y_val[\"y\"]\n",
    "\n",
    "X_train_z = X_train[[\"az1\", \"gz1\", \"mz1\"]]\n",
    "X_test_z = X_test[[\"az1\", \"gz1\", \"mz1\"]]\n",
    "X_val_z = X_val[[\"az1\", \"gz1\", \"mz1\"]]\n",
    "y_train_z = y_train[\"z\"]\n",
    "y_test_z = y_test[\"z\"]\n",
    "y_val_z = y_val[\"z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b5987",
   "metadata": {},
   "source": [
    "### Model to predict x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3377c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_x = X_train_x.values.reshape(len(X_train_x), len(X_train_x.columns), 1)\n",
    "X_test_x = X_test_x.values.reshape(len(X_test_x), len(X_test_x.columns), 1)\n",
    "X_val_x = X_val_x.values.reshape(len(X_val_x), len(X_val_x.columns), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f7f5646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_21 (Conv1D)          (None, None, 32)          128       \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,281\n",
      "Trainable params: 3,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(32, (3), activation='relu', input_shape= [None, 1]))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b39235ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"Adam\", loss = \"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4b9b733b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "34/34 [==============================] - 3s 28ms/step - loss: 0.9565 - val_loss: 0.6384\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.4280 - val_loss: 0.6615\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.4171 - val_loss: 0.6791\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.4094 - val_loss: 0.7023\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.4034 - val_loss: 0.7332\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3976 - val_loss: 0.7605\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3935 - val_loss: 0.8000\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3880 - val_loss: 0.8399\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3855 - val_loss: 0.8669\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3801 - val_loss: 0.8866\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3784 - val_loss: 0.8978\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3761 - val_loss: 0.9369\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3732 - val_loss: 0.9828\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3726 - val_loss: 0.9949\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3691 - val_loss: 1.0656\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3648 - val_loss: 1.1990\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3701 - val_loss: 1.1393\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3642 - val_loss: 1.2118\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3621 - val_loss: 1.1634\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3650 - val_loss: 1.2272\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3617 - val_loss: 1.2528\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3592 - val_loss: 1.2850\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3590 - val_loss: 1.3155\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3577 - val_loss: 1.3130\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3570 - val_loss: 1.3119\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3563 - val_loss: 1.3339\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3553 - val_loss: 1.3627\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3558 - val_loss: 1.3459\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3535 - val_loss: 1.4238\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3562 - val_loss: 1.3332\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3502 - val_loss: 1.3557\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3505 - val_loss: 1.3165\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3495 - val_loss: 1.3303\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3506 - val_loss: 1.3885\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3481 - val_loss: 1.4161\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3512 - val_loss: 1.3249\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3497 - val_loss: 1.2333\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3487 - val_loss: 1.4202\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3482 - val_loss: 1.3713\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3474 - val_loss: 1.4011\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3436 - val_loss: 1.3920\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3433 - val_loss: 1.4120\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3458 - val_loss: 1.3508\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3478 - val_loss: 1.3439\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3411 - val_loss: 1.3748\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3423 - val_loss: 1.4265\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3454 - val_loss: 1.3785\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3388 - val_loss: 1.4451\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3416 - val_loss: 1.4193\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3373 - val_loss: 1.3386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cb7a526f70>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_x, y_train_x, epochs = 50, validation_data = (X_val_x, y_val_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "30a01a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_x = model.predict(X_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "78ae5b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual x</th>\n",
       "      <th>Predicted x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.871833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>1.5000</td>\n",
       "      <td>6.750217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>1.5000</td>\n",
       "      <td>5.086530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.3675</td>\n",
       "      <td>7.330701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0.9150</td>\n",
       "      <td>7.044955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.745916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.755970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1.5000</td>\n",
       "      <td>6.840972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>0.6150</td>\n",
       "      <td>6.032866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>1.5000</td>\n",
       "      <td>5.335437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual x  Predicted x\n",
       "210     0.0000     6.871833\n",
       "638     1.5000     6.750217\n",
       "781     1.5000     5.086530\n",
       "348     0.3675     7.330701\n",
       "421     0.9150     7.044955\n",
       "...        ...          ...\n",
       "1286    0.0000     4.745916\n",
       "1466    0.0000     4.755970\n",
       "545     1.5000     6.840972\n",
       "1117    0.6150     6.032866\n",
       "802     1.5000     5.335437\n",
       "\n",
       "[335 rows x 2 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_x = pd.DataFrame({\"Actual x\": y_test_x,\n",
    "                            \"Predicted x\": predict_x.flatten()})\n",
    "dataframe_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79028df",
   "metadata": {},
   "source": [
    "### Model to predict y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c4ff8587",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_y = X_train_y.values.reshape(len(X_train_y), len(X_train_y.columns), 1)\n",
    "X_test_y = X_test_y.values.reshape(len(X_test_y), len(X_test_y.columns), 1)\n",
    "X_val_y = X_val_y.values.reshape(len(X_val_y), len(X_val_y.columns), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "30ebb9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_24 (Conv1D)          (None, None, 32)          128       \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,281\n",
      "Trainable params: 3,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(32, (3), activation='relu', input_shape= [None, 1]))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ff9a45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"Adam\", loss = \"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f2c7e8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 4s 28ms/step - loss: 27.5230 - val_loss: 23.4926\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 16.6773 - val_loss: 15.4017\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 12.0625 - val_loss: 12.2930\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 10.6328 - val_loss: 11.2189\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 10.1569 - val_loss: 10.8246\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.9576 - val_loss: 10.6214\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.8686 - val_loss: 10.5465\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.8224 - val_loss: 10.4776\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.7857 - val_loss: 10.4558\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.7561 - val_loss: 10.4540\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.7282 - val_loss: 10.4269\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.6928 - val_loss: 10.4361\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.6678 - val_loss: 10.4441\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.6424 - val_loss: 10.3721\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.6214 - val_loss: 10.4222\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.6062 - val_loss: 10.3648\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5926 - val_loss: 10.3911\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5862 - val_loss: 10.3937\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5760 - val_loss: 10.3494\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5775 - val_loss: 10.3604\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.5594 - val_loss: 10.3461\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5545 - val_loss: 10.3458\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5584 - val_loss: 10.3653\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5456 - val_loss: 10.3445\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.5475 - val_loss: 10.3352\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.5454 - val_loss: 10.3708\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5356 - val_loss: 10.3471\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.5372 - val_loss: 10.3507\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5317 - val_loss: 10.3461\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.5290 - val_loss: 10.3532\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5351 - val_loss: 10.3306\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.5231 - val_loss: 10.3602\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5224 - val_loss: 10.3558\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5329 - val_loss: 10.3318\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5260 - val_loss: 10.3518\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5161 - val_loss: 10.3638\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5160 - val_loss: 10.3517\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5157 - val_loss: 10.3650\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.5119 - val_loss: 10.3583\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5177 - val_loss: 10.3516\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.5119 - val_loss: 10.3749\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.5105 - val_loss: 10.3377\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.5019 - val_loss: 10.3693\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5058 - val_loss: 10.3705\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.5025 - val_loss: 10.3715\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5019 - val_loss: 10.3615\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4993 - val_loss: 10.3744\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.5020 - val_loss: 10.3593\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4983 - val_loss: 10.3849\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4942 - val_loss: 10.3720\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.4953 - val_loss: 10.3590\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4891 - val_loss: 10.3750\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4899 - val_loss: 10.3888\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.4901 - val_loss: 10.3735\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4906 - val_loss: 10.3661\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.4884 - val_loss: 10.3925\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.4863 - val_loss: 10.3778\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4824 - val_loss: 10.3890\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4982 - val_loss: 10.3746\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4787 - val_loss: 10.3912\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4884 - val_loss: 10.3690\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4774 - val_loss: 10.3973\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.4729 - val_loss: 10.3682\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4745 - val_loss: 10.3805\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.4819 - val_loss: 10.4082\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4691 - val_loss: 10.3770\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.4735 - val_loss: 10.3912\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4765 - val_loss: 10.3578\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4682 - val_loss: 10.3943\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.4898 - val_loss: 10.3952\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4635 - val_loss: 10.3596\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4667 - val_loss: 10.4080\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.4667 - val_loss: 10.4150\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4715 - val_loss: 10.3998\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4567 - val_loss: 10.3884\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4704 - val_loss: 10.3863\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4551 - val_loss: 10.4072\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4548 - val_loss: 10.4043\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.4487 - val_loss: 10.3973\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.4509 - val_loss: 10.3856\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.4565 - val_loss: 10.3929\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.4422 - val_loss: 10.4112\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.4504 - val_loss: 10.4115\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.4415 - val_loss: 10.3977\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.4451 - val_loss: 10.3989\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4450 - val_loss: 10.4176\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4350 - val_loss: 10.3918\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4417 - val_loss: 10.4346\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4390 - val_loss: 10.4366\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.4743 - val_loss: 10.5066\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.4458 - val_loss: 10.4086\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.4277 - val_loss: 10.4207\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.4263 - val_loss: 10.4201\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.4318 - val_loss: 10.4344\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.4213 - val_loss: 10.4401\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.4421 - val_loss: 10.4074\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4216 - val_loss: 10.4723\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4269 - val_loss: 10.4432\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4169 - val_loss: 10.4077\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4236 - val_loss: 10.4125\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4228 - val_loss: 10.3957\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4216 - val_loss: 10.4103\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.4121 - val_loss: 10.4487\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4043 - val_loss: 10.4377\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.4061 - val_loss: 10.4155\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.4132 - val_loss: 10.4277\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4041 - val_loss: 10.4238\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3940 - val_loss: 10.4499\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4110 - val_loss: 10.4771\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4013 - val_loss: 10.4168\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.3940 - val_loss: 10.4463\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4012 - val_loss: 10.4574\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3933 - val_loss: 10.4199\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.4037 - val_loss: 10.4493\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3916 - val_loss: 10.4065\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3923 - val_loss: 10.4720\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3747 - val_loss: 10.4162\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4142 - val_loss: 10.4880\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3886 - val_loss: 10.4304\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3925 - val_loss: 10.4696\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3925 - val_loss: 10.4439\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3791 - val_loss: 10.4593\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3943 - val_loss: 10.4886\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3766 - val_loss: 10.4720\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3875 - val_loss: 10.5002\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3801 - val_loss: 10.4547\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.4042 - val_loss: 10.4504\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.3734 - val_loss: 10.4597\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3703 - val_loss: 10.4671\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3881 - val_loss: 10.4879\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.3714 - val_loss: 10.4418\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.4000 - val_loss: 10.4488\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3718 - val_loss: 10.4920\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3760 - val_loss: 10.5006\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.3909 - val_loss: 10.5239\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3712 - val_loss: 10.4569\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3708 - val_loss: 10.4814\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3588 - val_loss: 10.4762\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3631 - val_loss: 10.4695\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3541 - val_loss: 10.4738\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3512 - val_loss: 10.4744\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3538 - val_loss: 10.4882\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.3734 - val_loss: 10.4611\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3590 - val_loss: 10.4951\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3645 - val_loss: 10.4570\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3536 - val_loss: 10.4677\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3640 - val_loss: 10.5016\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3385 - val_loss: 10.4859\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3504 - val_loss: 10.5399\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.3460 - val_loss: 10.4757\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3409 - val_loss: 10.4852\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3451 - val_loss: 10.5237\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3459 - val_loss: 10.4757\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3679 - val_loss: 10.5165\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3404 - val_loss: 10.5047\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3541 - val_loss: 10.5088\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3432 - val_loss: 10.4911\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3323 - val_loss: 10.5303\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.3707 - val_loss: 10.5055\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3469 - val_loss: 10.4804\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3183 - val_loss: 10.5220\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3231 - val_loss: 10.4872\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.3226 - val_loss: 10.5084\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3201 - val_loss: 10.4964\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3287 - val_loss: 10.5415\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3268 - val_loss: 10.5236\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3772 - val_loss: 10.5897\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3310 - val_loss: 10.4832\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3201 - val_loss: 10.5251\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.3119 - val_loss: 10.5155\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.3147 - val_loss: 10.5077\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3115 - val_loss: 10.5398\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3002 - val_loss: 10.5112\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3074 - val_loss: 10.5337\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3298 - val_loss: 10.5202\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3435 - val_loss: 10.5740\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3354 - val_loss: 10.5305\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3117 - val_loss: 10.5151\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.3082 - val_loss: 10.5434\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3013 - val_loss: 10.5184\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3288 - val_loss: 10.5106\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3058 - val_loss: 10.5182\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.2996 - val_loss: 10.5093\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.2970 - val_loss: 10.5210\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.2895 - val_loss: 10.5291\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.2892 - val_loss: 10.5390\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.2939 - val_loss: 10.5151\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.2956 - val_loss: 10.5778\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.3061 - val_loss: 10.5314\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.2846 - val_loss: 10.5432\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3195 - val_loss: 10.5235\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3098 - val_loss: 10.5493\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3076 - val_loss: 10.5404\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.2861 - val_loss: 10.5378\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.2813 - val_loss: 10.5479\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 9.2824 - val_loss: 10.5391\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.3096 - val_loss: 10.5273\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.2730 - val_loss: 10.5420\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.2839 - val_loss: 10.5316\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.2749 - val_loss: 10.5439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cb0dca6160>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_y, y_train_y, epochs = 200, validation_data = (X_val_y, y_val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "27a3f27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_y = model.predict(X_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d7d6dbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual y</th>\n",
       "      <th>Predicted y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.7583</td>\n",
       "      <td>4.904576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>3.6120</td>\n",
       "      <td>5.301539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>4.7560</td>\n",
       "      <td>5.046751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>2.5000</td>\n",
       "      <td>5.031599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>2.5000</td>\n",
       "      <td>4.922308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>7.5095</td>\n",
       "      <td>4.711534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>9.5981</td>\n",
       "      <td>5.043408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2.8680</td>\n",
       "      <td>5.252265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>6.5000</td>\n",
       "      <td>6.341801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>4.9240</td>\n",
       "      <td>5.382780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual y  Predicted y\n",
       "210     1.7583     4.904576\n",
       "638     3.6120     5.301539\n",
       "781     4.7560     5.046751\n",
       "348     2.5000     5.031599\n",
       "421     2.5000     4.922308\n",
       "...        ...          ...\n",
       "1286    7.5095     4.711534\n",
       "1466    9.5981     5.043408\n",
       "545     2.8680     5.252265\n",
       "1117    6.5000     6.341801\n",
       "802     4.9240     5.382780\n",
       "\n",
       "[335 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_y = pd.DataFrame({\"Actual y\": y_test_y,\n",
    "                            \"Predicted y\": predict_y.flatten()})\n",
    "dataframe_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f9a3b",
   "metadata": {},
   "source": [
    "### Model to predict z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "974e9e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_z = X_train_z.values.reshape(len(X_train_z), len(X_train_z.columns), 1)\n",
    "X_test_z = X_test_z.values.reshape(len(X_test_z), len(X_test_z.columns), 1)\n",
    "X_val_z = X_val_z.values.reshape(len(X_val_z), len(X_val_z.columns), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c923e2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_25 (Conv1D)          (None, None, 32)          128       \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,281\n",
      "Trainable params: 3,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(32, (3), activation='relu', input_shape= [None, 1]))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "50f4f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"Adam\", loss = \"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "be38ad91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 4s 28ms/step - loss: 1.1986 - val_loss: 0.9558\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.9011 - val_loss: 0.8516\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.8331 - val_loss: 0.7870\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.8132 - val_loss: 0.8129\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.8058 - val_loss: 0.7715\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7980 - val_loss: 0.7586\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7953 - val_loss: 0.7677\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7923 - val_loss: 0.7512\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7905 - val_loss: 0.7594\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7907 - val_loss: 0.7458\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7931 - val_loss: 0.7492\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7857 - val_loss: 0.7498\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7903 - val_loss: 0.7591\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7816 - val_loss: 0.7878\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7796 - val_loss: 0.7398\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7837 - val_loss: 0.7339\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7698 - val_loss: 0.7297\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7905 - val_loss: 0.7485\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7723 - val_loss: 0.7473\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7823 - val_loss: 0.7707\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7709 - val_loss: 0.7329\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7636 - val_loss: 0.7706\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7832 - val_loss: 0.7265\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7707 - val_loss: 0.7228\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7649 - val_loss: 0.7359\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7658 - val_loss: 0.7659\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7692 - val_loss: 0.7193\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7580 - val_loss: 0.7244\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7507 - val_loss: 0.7381\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7627 - val_loss: 0.7306\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7525 - val_loss: 0.7255\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7453 - val_loss: 0.7119\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7472 - val_loss: 0.7372\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7417 - val_loss: 0.7115\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7392 - val_loss: 0.7268\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7403 - val_loss: 0.7269\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7310 - val_loss: 0.7049\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7371 - val_loss: 0.7352\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7289 - val_loss: 0.7104\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7409 - val_loss: 0.7244\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7440 - val_loss: 0.7077\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7284 - val_loss: 0.7007\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7204 - val_loss: 0.7018\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7227 - val_loss: 0.6914\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7304 - val_loss: 0.7041\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7125 - val_loss: 0.6970\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7152 - val_loss: 0.7454\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7116 - val_loss: 0.6909\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7103 - val_loss: 0.6880\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7143 - val_loss: 0.6918\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7021 - val_loss: 0.6923\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7071 - val_loss: 0.6880\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6945 - val_loss: 0.6835\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7028 - val_loss: 0.7065\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6987 - val_loss: 0.6996\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6999 - val_loss: 0.6771\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6944 - val_loss: 0.7523\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7047 - val_loss: 0.7167\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7002 - val_loss: 0.7103\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6996 - val_loss: 0.6899\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6885 - val_loss: 0.6861\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6917 - val_loss: 0.6996\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6936 - val_loss: 0.6836\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6844 - val_loss: 0.6780\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6974 - val_loss: 0.6816\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6819 - val_loss: 0.6983\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6795 - val_loss: 0.6703\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7015 - val_loss: 0.6824\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6854 - val_loss: 0.6751\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7014 - val_loss: 0.6766\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6853 - val_loss: 0.6957\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6943 - val_loss: 0.6726\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6790 - val_loss: 0.6797\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6825 - val_loss: 0.6788\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6773 - val_loss: 0.6793\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6747 - val_loss: 0.6656\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6971 - val_loss: 0.6751\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6755 - val_loss: 0.7049\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6772 - val_loss: 0.6663\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6741 - val_loss: 0.6926\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6801 - val_loss: 0.7113\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6763 - val_loss: 0.7174\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6738 - val_loss: 0.6643\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6761 - val_loss: 0.6662\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6778 - val_loss: 0.6819\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6791 - val_loss: 0.6725\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6639 - val_loss: 0.6657\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6649 - val_loss: 0.6908\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6627 - val_loss: 0.6769\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6774 - val_loss: 0.6721\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6890 - val_loss: 0.6711\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6588 - val_loss: 0.7238\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6579 - val_loss: 0.6712\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6632 - val_loss: 0.7074\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6654 - val_loss: 0.6808\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6529 - val_loss: 0.6722\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6534 - val_loss: 0.8000\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6678 - val_loss: 0.6737\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6519 - val_loss: 0.6607\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6516 - val_loss: 0.6547\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6463 - val_loss: 0.6974\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6446 - val_loss: 0.6622\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6370 - val_loss: 0.6645\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6465 - val_loss: 0.6596\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6704 - val_loss: 0.6653\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6496 - val_loss: 0.6692\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6493 - val_loss: 0.6913\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6391 - val_loss: 0.6616\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6468 - val_loss: 0.7541\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6570 - val_loss: 0.6576\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6407 - val_loss: 0.6681\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6539 - val_loss: 0.6972\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6477 - val_loss: 0.6585\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6309 - val_loss: 0.6853\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6566 - val_loss: 0.6460\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6294 - val_loss: 0.7055\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6292 - val_loss: 0.6711\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6334 - val_loss: 0.6475\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6285 - val_loss: 0.6409\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6220 - val_loss: 0.6409\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6346 - val_loss: 0.6638\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6173 - val_loss: 0.6528\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6301 - val_loss: 0.6707\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6314 - val_loss: 0.6629\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6232 - val_loss: 0.6494\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6161 - val_loss: 0.6289\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6334 - val_loss: 0.6520\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6135 - val_loss: 0.6453\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6106 - val_loss: 0.6535\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6087 - val_loss: 0.6645\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6031 - val_loss: 0.6562\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6112 - val_loss: 0.6391\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6089 - val_loss: 0.6741\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6176 - val_loss: 0.7627\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6120 - val_loss: 0.6277\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6242 - val_loss: 0.6312\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6183 - val_loss: 0.6753\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6024 - val_loss: 0.6382\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6026 - val_loss: 0.6546\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6008 - val_loss: 0.6824\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6222 - val_loss: 0.6718\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6085 - val_loss: 0.6795\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5999 - val_loss: 0.6497\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6206 - val_loss: 0.6865\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6078 - val_loss: 0.6265\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6068 - val_loss: 0.6562\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6040 - val_loss: 0.6229\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6071 - val_loss: 0.6202\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5914 - val_loss: 0.6316\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5942 - val_loss: 0.7191\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6070 - val_loss: 0.6529\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5881 - val_loss: 0.6771\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5930 - val_loss: 0.6327\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5861 - val_loss: 0.6478\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6061 - val_loss: 0.6123\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6033 - val_loss: 0.7146\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5984 - val_loss: 0.6558\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5884 - val_loss: 0.6576\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5922 - val_loss: 0.6338\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5841 - val_loss: 0.6218\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5949 - val_loss: 0.6153\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5941 - val_loss: 0.6481\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5863 - val_loss: 0.6186\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 0.6189\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5813 - val_loss: 0.6366\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5753 - val_loss: 0.6485\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5891 - val_loss: 0.6239\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6001 - val_loss: 0.6168\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5902 - val_loss: 0.6088\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5764 - val_loss: 0.6634\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5762 - val_loss: 0.6580\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5867 - val_loss: 0.6368\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5742 - val_loss: 0.6089\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5964 - val_loss: 0.7257\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5870 - val_loss: 0.6240\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5687 - val_loss: 0.6138\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5694 - val_loss: 0.6131\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5724 - val_loss: 0.6515\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5680 - val_loss: 0.6039\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5874 - val_loss: 0.5997\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5787 - val_loss: 0.6263\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5644 - val_loss: 0.5963\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5755 - val_loss: 0.6118\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5767 - val_loss: 0.6127\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5695 - val_loss: 0.6062\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5632 - val_loss: 0.6295\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5586 - val_loss: 0.6257\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5545 - val_loss: 0.6260\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5656 - val_loss: 0.6092\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5723 - val_loss: 0.6754\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5998 - val_loss: 0.6401\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5796 - val_loss: 0.6217\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5564 - val_loss: 0.6007\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5561 - val_loss: 0.6160\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5524 - val_loss: 0.5980\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5542 - val_loss: 0.6170\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5660 - val_loss: 0.6830\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5537 - val_loss: 0.5951\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5526 - val_loss: 0.6404\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5464 - val_loss: 0.5943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cb0c6a4430>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_z, y_train_z, epochs = 200, validation_data = (X_val_z, y_val_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c192f399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_z = model.predict(X_test_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "54cce058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual z</th>\n",
       "      <th>Predicted z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.206454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>1.09750</td>\n",
       "      <td>1.236608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>1.45500</td>\n",
       "      <td>1.912746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.18375</td>\n",
       "      <td>0.690421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0.45750</td>\n",
       "      <td>1.155269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>2.50000</td>\n",
       "      <td>1.129770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>2.50000</td>\n",
       "      <td>2.026640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0.86500</td>\n",
       "      <td>1.306689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>2.29500</td>\n",
       "      <td>2.210670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>1.50750</td>\n",
       "      <td>1.358613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual z  Predicted z\n",
       "210    0.00000     1.206454\n",
       "638    1.09750     1.236608\n",
       "781    1.45500     1.912746\n",
       "348    0.18375     0.690421\n",
       "421    0.45750     1.155269\n",
       "...        ...          ...\n",
       "1286   2.50000     1.129770\n",
       "1466   2.50000     2.026640\n",
       "545    0.86500     1.306689\n",
       "1117   2.29500     2.210670\n",
       "802    1.50750     1.358613\n",
       "\n",
       "[335 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_z = pd.DataFrame({\"Actual z\": y_test_z,\n",
    "                            \"Predicted z\": predict_z.flatten()})\n",
    "dataframe_z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b8f6c9",
   "metadata": {},
   "source": [
    "### Combine Data Frames x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "97894994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual x</th>\n",
       "      <th>Predicted x</th>\n",
       "      <th>Actual y</th>\n",
       "      <th>Predicted y</th>\n",
       "      <th>Actual z</th>\n",
       "      <th>Predicted z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.871833</td>\n",
       "      <td>1.7583</td>\n",
       "      <td>4.904576</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.206454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>1.5000</td>\n",
       "      <td>6.750217</td>\n",
       "      <td>3.6120</td>\n",
       "      <td>5.301539</td>\n",
       "      <td>1.09750</td>\n",
       "      <td>1.236608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>1.5000</td>\n",
       "      <td>5.086530</td>\n",
       "      <td>4.7560</td>\n",
       "      <td>5.046751</td>\n",
       "      <td>1.45500</td>\n",
       "      <td>1.912746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.3675</td>\n",
       "      <td>7.330701</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>5.031599</td>\n",
       "      <td>0.18375</td>\n",
       "      <td>0.690421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0.9150</td>\n",
       "      <td>7.044955</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>4.922308</td>\n",
       "      <td>0.45750</td>\n",
       "      <td>1.155269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.745916</td>\n",
       "      <td>7.5095</td>\n",
       "      <td>4.711534</td>\n",
       "      <td>2.50000</td>\n",
       "      <td>1.129770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.755970</td>\n",
       "      <td>9.5981</td>\n",
       "      <td>5.043408</td>\n",
       "      <td>2.50000</td>\n",
       "      <td>2.026640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1.5000</td>\n",
       "      <td>6.840972</td>\n",
       "      <td>2.8680</td>\n",
       "      <td>5.252265</td>\n",
       "      <td>0.86500</td>\n",
       "      <td>1.306689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>0.6150</td>\n",
       "      <td>6.032866</td>\n",
       "      <td>6.5000</td>\n",
       "      <td>6.341801</td>\n",
       "      <td>2.29500</td>\n",
       "      <td>2.210670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>1.5000</td>\n",
       "      <td>5.335437</td>\n",
       "      <td>4.9240</td>\n",
       "      <td>5.382780</td>\n",
       "      <td>1.50750</td>\n",
       "      <td>1.358613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual x  Predicted x  Actual y  Predicted y  Actual z  Predicted z\n",
       "210     0.0000     6.871833    1.7583     4.904576   0.00000     1.206454\n",
       "638     1.5000     6.750217    3.6120     5.301539   1.09750     1.236608\n",
       "781     1.5000     5.086530    4.7560     5.046751   1.45500     1.912746\n",
       "348     0.3675     7.330701    2.5000     5.031599   0.18375     0.690421\n",
       "421     0.9150     7.044955    2.5000     4.922308   0.45750     1.155269\n",
       "...        ...          ...       ...          ...       ...          ...\n",
       "1286    0.0000     4.745916    7.5095     4.711534   2.50000     1.129770\n",
       "1466    0.0000     4.755970    9.5981     5.043408   2.50000     2.026640\n",
       "545     1.5000     6.840972    2.8680     5.252265   0.86500     1.306689\n",
       "1117    0.6150     6.032866    6.5000     6.341801   2.29500     2.210670\n",
       "802     1.5000     5.335437    4.9240     5.382780   1.50750     1.358613\n",
       "\n",
       "[335 rows x 6 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicion_data = pd.concat([dataframe_x, dataframe_y, dataframe_z], axis = 1)\n",
    "predicion_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab136ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
