{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "912246ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jazi\n",
      "[nltk_data]     Designs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import keras.utils\n",
    "import time\n",
    "from keras.callbacks import TensorBoard, CSVLogger\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.models import load_model\n",
    "from nltk.corpus import stopwords\n",
    "import operator\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "nltk.download('stopwords')\n",
    "tokenizer=RegexpTokenizer(r'\\w+')\n",
    "ps=PorterStemmer()\n",
    "en_stop=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "d238a6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "dd59d433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2635.json</th>\n",
       "      <th>False</th>\n",
       "      <th>Says the Annies List political group supports third-trimester abortions on demand.</th>\n",
       "      <th>abortion</th>\n",
       "      <th>dwayne-bohac</th>\n",
       "      <th>State representative</th>\n",
       "      <th>Texas</th>\n",
       "      <th>republican</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>a mailer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>False</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12465.json</td>\n",
       "      <td>True</td>\n",
       "      <td>The Chicago Bears have had more starting quart...</td>\n",
       "      <td>education</td>\n",
       "      <td>robin-vos</td>\n",
       "      <td>Wisconsin Assembly speaker</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>republican</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>a an online opinion-piece</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    2635.json        False  \\\n",
       "0  10540.json    half-true   \n",
       "1    324.json  mostly-true   \n",
       "2   1123.json        False   \n",
       "3   9028.json    half-true   \n",
       "4  12465.json         True   \n",
       "\n",
       "  Says the Annies List political group supports third-trimester abortions on demand.  \\\n",
       "0  When did the decline of coal start? It started...                                   \n",
       "1  Hillary Clinton agrees with John McCain \"by vo...                                   \n",
       "2  Health care reform legislation is likely to ma...                                   \n",
       "3  The economic turnaround started at the end of ...                                   \n",
       "4  The Chicago Bears have had more starting quart...                                   \n",
       "\n",
       "                             abortion    dwayne-bohac  \\\n",
       "0  energy,history,job-accomplishments  scott-surovell   \n",
       "1                      foreign-policy    barack-obama   \n",
       "2                         health-care    blog-posting   \n",
       "3                        economy,jobs   charlie-crist   \n",
       "4                           education       robin-vos   \n",
       "\n",
       "         State representative      Texas  republican  0.1   1  0.2  0.3  0.4  \\\n",
       "0              State delegate   Virginia    democrat    0   0    1    1    0   \n",
       "1                   President   Illinois    democrat   70  71  160  163    9   \n",
       "2                         NaN        NaN        none    7  19    3    5   44   \n",
       "3                         NaN    Florida    democrat   15   9   20   19    2   \n",
       "4  Wisconsin Assembly speaker  Wisconsin  republican    0   3    2    5    1   \n",
       "\n",
       "                    a mailer  \n",
       "0            a floor speech.  \n",
       "1                     Denver  \n",
       "2             a news release  \n",
       "3        an interview on CNN  \n",
       "4  a an online opinion-piece  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake = pd.read_excel('train.xlsx')\n",
    "df_fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "faec0527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10268, 14)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = df_fake.apply(lambda x: x.astype(str).str.lower())\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "f47a8799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label', 'statement', 'subject', 'speaker', 'job', 'state',\n",
       "       'party', 'barely-true', 'false', 'half-true', 'mostly-true',\n",
       "       'pants-fire', 'venue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols =[\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"job\", \"state\", \"party\",\n",
    "                                            \"barely-true\", \"false\", \"half-true\", \"mostly-true\", \"pants-fire\", \"venue\"]\n",
    "train_data.columns=feature_cols\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "0fe1b957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "label          0\n",
       "statement      0\n",
       "subject        0\n",
       "speaker        0\n",
       "job            0\n",
       "state          0\n",
       "party          0\n",
       "barely-true    0\n",
       "false          0\n",
       "half-true      0\n",
       "mostly-true    0\n",
       "pants-fire     0\n",
       "venue          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "3fc2c5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['half-true' 'mostly-true' 'false' 'true' 'barely-true' 'pants-fire']\n"
     ]
    }
   ],
   "source": [
    "print(train_data.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "d6ec4adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10268 entries, 0 to 10267\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           10268 non-null  object\n",
      " 1   label        10268 non-null  object\n",
      " 2   statement    10268 non-null  object\n",
      " 3   subject      10268 non-null  object\n",
      " 4   speaker      10268 non-null  object\n",
      " 5   job          10268 non-null  object\n",
      " 6   state        10268 non-null  object\n",
      " 7   party        10268 non-null  object\n",
      " 8   barely-true  10268 non-null  object\n",
      " 9   false        10268 non-null  object\n",
      " 10  half-true    10268 non-null  object\n",
      " 11  mostly-true  10268 non-null  object\n",
      " 12  pants-fire   10268 non-null  object\n",
      " 13  venue        10268 non-null  object\n",
      "dtypes: object(14)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039a25eb",
   "metadata": {},
   "source": [
    "## Label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "80b67436",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label_dict = {\"pants-fire\" : 0, \"false\" : 1, \"barely-true\" : 2, \"half-true\" : 3, \"mostly-true\" : 4, \"true\" : 5}\n",
    "train_data['output'] = train_data['label'].apply(lambda x: y_label_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "9272f392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    2123\n",
       "1    1997\n",
       "4    1966\n",
       "5    1683\n",
       "2    1657\n",
       "0     842\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['output'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e1fd7a",
   "metadata": {},
   "source": [
    "## Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "ae9bb921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'barack-obama': 0,\n",
       " 'donald-trump': 1,\n",
       " 'hillary-clinton': 2,\n",
       " 'mitt-romney': 3,\n",
       " 'scott-walker': 4,\n",
       " 'john-mccain': 5,\n",
       " 'rick-perry': 6,\n",
       " 'chain-email': 7,\n",
       " 'marco-rubio': 8,\n",
       " 'viral-image': 13,\n",
       " 'rick-scott': 9,\n",
       " 'ted-cruz': 10,\n",
       " 'bernie-s': 11,\n",
       " 'newt-gingrich': 16,\n",
       " 'chris-christie': 12,\n",
       " 'facebook-posts': 13,\n",
       " 'blog-posting': 13,\n",
       " 'charlie-crist': 14,\n",
       " 'congressional': 15,\n",
       " 'republican': 15,\n",
       " 'national-committe': 15,\n",
       " 'democratic': 15}"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_speakers = {'barack-obama' : 0, 'donald-trump' : 1, 'hillary-clinton' : 2, \n",
    "                     'mitt-romney' : 3, 'scott-walker' : 4, 'john-mccain' : 5, \n",
    "                     'rick-perry' : 6, 'chain-email' : 7, 'marco-rubio' : 8, 'viral-image':13,\n",
    "                     'rick-scott' : 9, 'ted-cruz' : 10, 'bernie-s' : 11, 'newt-gingrich':16,\n",
    "                     'chris-christie' : 12, 'facebook-posts' : 13,'blog-posting':13, \n",
    "                     'charlie-crist' : 14, 'congressional' : 15, 'republican' : 15, \n",
    "                     'national-committe' : 15, 'democratic':15}\n",
    "\n",
    "frequent_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "bfbb6659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17    7363\n",
       "0      493\n",
       "15     347\n",
       "1      276\n",
       "2      239\n",
       "3      180\n",
       "13     156\n",
       "4      150\n",
       "5      148\n",
       "6      142\n",
       "7      142\n",
       "8      117\n",
       "9      116\n",
       "10      93\n",
       "11      89\n",
       "12      78\n",
       "14      70\n",
       "16      69\n",
       "Name: speaker_id, dtype: int64"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_speaker_id(speaker):\n",
    "    if isinstance(speaker, str):\n",
    "        matched = [sp for sp in frequent_speakers if sp in speaker.lower()]\n",
    "        if len(matched)>0:\n",
    "            return frequent_speakers[matched[0]]\n",
    "        else:\n",
    "            return len(set(frequent_speakers.values())) \n",
    "    else:\n",
    "        return len(set(frequent_speakers.values()))\n",
    "    \n",
    "train_data['speaker_id'] = train_data['speaker'].apply(get_speaker_id)\n",
    "train_data['speaker_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13d327e",
   "metadata": {},
   "source": [
    "## Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "29b0c8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    4608\n",
       "1     1219\n",
       "0     1203\n",
       "3      912\n",
       "2      896\n",
       "8      279\n",
       "9      254\n",
       "5      232\n",
       "4      224\n",
       "7      167\n",
       "11     150\n",
       "6      124\n",
       "Name: job_id, dtype: int64"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_jobs = { 'senator' : 0, 'president' : 1, 'governor' : 2, \n",
    "                 'u.s. representative' : 3, 'attorney' : 4, 'congressman' : 5, \n",
    "                 'congresswoman' : 5, 'social media posting' : 6, 'lawyer' : 4, \n",
    "                 'businessman' : 6,  'radio host' : 8, 'host':8,\n",
    "                  'mayor' : 7, 'assembly' : 9,'representative' : 3, \n",
    "                 'senate' : 9,'state representative' : 10,'milwaukee county executive' : 11,\n",
    "                 'u.s. house of representatives' : 3,'house representative' : 3,\n",
    "                 'house of representatives' : 3,'house member':3}\n",
    "\n",
    "\n",
    "def get_job_id(job):\n",
    "    if isinstance(job, str):\n",
    "        matched = [jb for jb in frequent_jobs if jb in job.lower() ]\n",
    "        if len(matched)>0:\n",
    "            return frequent_jobs[matched[0]]\n",
    "        else:\n",
    "            return len(set(frequent_jobs.values()))\n",
    "    else:\n",
    "        return len(set(frequent_jobs.values()))\n",
    "    \n",
    "    \n",
    "train_data['job_id'] = train_data['job'].apply(get_job_id)\n",
    "train_data['job_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e4cccd",
   "metadata": {},
   "source": [
    "# Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "27614d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'republican': 0, 'democrat': 1, 'none': 2, 'organization': 3, 'independent': 4}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    4509\n",
       "1    3346\n",
       "2    1746\n",
       "5     298\n",
       "3     220\n",
       "4     149\n",
       "Name: party_id, dtype: int64"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_parties = train_data['party'].str.lower().value_counts()[:5].reset_index().to_dict()['index']\n",
    "frequent_parties = dict((v,k) for k,v in frequent_parties.items())\n",
    "\n",
    "def get_party_id(party):\n",
    "    if isinstance(party, str):\n",
    "        matched = [pt for pt in frequent_parties if pt in party.lower() ]\n",
    "        if len(matched)>0:\n",
    "            return frequent_parties[matched[0]]\n",
    "        else:\n",
    "            return len(set(frequent_parties.values())) \n",
    "    else:\n",
    "        return len(set(frequent_parties.values()))\n",
    "    \n",
    "train_data['party_id'] = train_data['party'].apply(get_party_id)\n",
    "print(frequent_parties)\n",
    "train_data['party_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "75354e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: party, dtype: int64)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[train_data['party_id']==9]['party'].value_counts()[:90]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c77174",
   "metadata": {},
   "source": [
    "## States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "f4d1be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_states = ['wyoming', 'colorado', 'hawaii', 'tennessee', 'nevada', 'maine',\n",
    "                'north dakota', 'mississippi', 'south dakota', 'oklahoma', \n",
    "                'delaware', 'minnesota', 'north carolina', 'arkansas', 'indiana', \n",
    "                'maryland', 'louisiana', 'idaho', 'iowa', 'west virginia', \n",
    "                'michigan', 'kansas', 'utah', 'connecticut', 'montana', 'vermont', \n",
    "                'pennsylvania', 'alaska', 'kentucky', 'nebraska', 'new hampshire', \n",
    "                'missouri', 'south carolina', 'alabama', 'new mexico']\n",
    "frequent_states = {'texas': 1, 'florida': 2, 'wisconsin': 3, 'new york': 4, \n",
    "                    'illinois': 5, 'ohio': 6, 'georgia': 7, 'virginia': 8, \n",
    "                   'rhode island': 9, 'oregon': 10, 'new jersey': 11, \n",
    "                   'massachusetts': 12, 'arizona': 13, 'california': 14, \n",
    "                   'washington': 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "038fe1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'texas': 1, 'florida': 2, 'wisconsin': 3, 'new york': 4, 'illinois': 5, 'ohio': 6, 'georgia': 7, 'virginia': 8, 'rhode island': 9, 'oregon': 10, 'new jersey': 11, 'massachusetts': 12, 'arizona': 13, 'california': 14, 'washington': 15, 'wyoming': 0, 'colorado': 0, 'hawaii': 0, 'tennessee': 0, 'nevada': 0, 'maine': 0, 'north dakota': 0, 'mississippi': 0, 'south dakota': 0, 'oklahoma': 0, 'delaware': 0, 'minnesota': 0, 'north carolina': 0, 'arkansas': 0, 'indiana': 0, 'maryland': 0, 'louisiana': 0, 'idaho': 0, 'iowa': 0, 'west virginia': 0, 'michigan': 0, 'kansas': 0, 'utah': 0, 'connecticut': 0, 'montana': 0, 'vermont': 0, 'pennsylvania': 0, 'alaska': 0, 'kentucky': 0, 'nebraska': 0, 'new hampshire': 0, 'missouri': 0, 'south carolina': 0, 'alabama': 0, 'new mexico': 0}\n",
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16    2239\n",
       "0     1214\n",
       "1     1008\n",
       "2     1007\n",
       "3      717\n",
       "4      660\n",
       "5      564\n",
       "6      449\n",
       "7      434\n",
       "8      410\n",
       "9      373\n",
       "10     242\n",
       "11     241\n",
       "12     216\n",
       "13     182\n",
       "14     163\n",
       "15     149\n",
       "Name: state_id, dtype: int64"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for state in other_states:\n",
    "    frequent_states[state]=0\n",
    "\n",
    "print(frequent_states)\n",
    "\n",
    "\n",
    "def get_state_id(state):\n",
    "    if isinstance(state, str):\n",
    "        if state.lower().rstrip() in frequent_states:\n",
    "            return frequent_states[state.lower().rstrip()]\n",
    "        else:\n",
    "            if 'washington' in state.lower():\n",
    "                return frequent_states['washington']\n",
    "            else:\n",
    "                return len(set(frequent_states.values()))\n",
    "    else:\n",
    "        return len(set(frequent_states.values()))\n",
    "\n",
    "\n",
    "train_data['state_id'] = train_data['state'].apply(get_state_id)\n",
    "\n",
    "print(len(set(frequent_states.values())))\n",
    "\n",
    "train_data['state_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72a9503",
   "metadata": {},
   "source": [
    "## Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "a25b0a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6     2112\n",
       "14    1912\n",
       "0     1308\n",
       "1      906\n",
       "4      623\n",
       "3      570\n",
       "5      513\n",
       "2      507\n",
       "11     439\n",
       "8      410\n",
       "9      305\n",
       "7      279\n",
       "10     172\n",
       "13     127\n",
       "12      85\n",
       "Name: subject_id, dtype: int64"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_subjects = {'health': 0, 'tax': 1, 'immigration': 2, 'election': 3, \n",
    "                     'education': 4, 'candidates-biography': 5, 'economy': 6, \n",
    "                     'gun': 7, 'job': 8, 'federal-budget': 6, 'energy': 9, \n",
    "                     'abortion': 10, 'foreign-policy': 6, 'state-budget': 6, \n",
    "                     'crime': 11, 'gays-and-lesbians' : 12, 'medicare' : 0, \n",
    "                     'terrorism' : 11, 'finance' : 6, 'criminal':11,\n",
    "                     'transportation':13}\n",
    "\n",
    "\n",
    "def get_subject_id(subject):\n",
    "    if isinstance(subject, str):\n",
    "        matched = [sbj for sbj in frequent_subjects if sbj in subject.lower()]\n",
    "        if len(matched)>0:\n",
    "            return frequent_subjects[matched[0]]\n",
    "        else:\n",
    "            return len(set(frequent_subjects.values())) \n",
    "    else:\n",
    "        return len(set(frequent_subjects.values()))\n",
    "\n",
    "    \n",
    "train_data['subject_id'] = train_data['subject'].apply(get_subject_id)\n",
    "print(len(set(frequent_subjects.values())))\n",
    "train_data['subject_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ae0faf",
   "metadata": {},
   "source": [
    "## Venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "2652ca46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'news release': 0, 'interview': 1, 'press release': 2, 'speech': 3, 'tv': 4, 'tweet': 5, 'campaign': 6, 'television': 4, 'debate': 7, 'news conference': 8, 'facebook': 5, 'press conference': 8, 'radio': 9, 'e-mail': 10, 'email': 10, 'mail': 10, 'social media': 5, 'twitter': 5, 'blog': 11, 'article': 11, 'comment': 12, 'web': 11}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13    2699\n",
       "1     1761\n",
       "3     1062\n",
       "7      738\n",
       "6      682\n",
       "4      570\n",
       "11     529\n",
       "5      473\n",
       "10     356\n",
       "2      347\n",
       "12     339\n",
       "0      325\n",
       "8      249\n",
       "9      138\n",
       "Name: venue_id, dtype: int64"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_venues = {'news release' : 0, 'interview' : 1, 'press release' : 2, \n",
    "                   'speech' : 3, 'tv' : 4, 'tweet' : 5, 'campaign' : 6, \n",
    "                   'television' : 4, 'debate' : 7, 'news conference' : 8, \n",
    "                   'facebook' : 5, 'press conference' : 8, 'radio' : 9, \n",
    "                   'e-mail' : 10, 'email' : 10, 'mail' : 10, 'social media' : 5,\n",
    "                   'twitter' : 5, 'blog':11, 'article':11,'comment':12, 'web':11}\n",
    "\n",
    "\n",
    "def get_venue_id(venue):\n",
    "    if isinstance(venue, str):\n",
    "        matched = [ven for ven in frequent_venues if ven in venue.lower()]\n",
    "        if len(matched)>0:\n",
    "            return frequent_venues[matched[0]]\n",
    "        else:\n",
    "            return len(set(frequent_venues.values())) \n",
    "    else:\n",
    "        return len(set(frequent_venues.values()))\n",
    "    \n",
    "\n",
    "train_data['venue_id'] = train_data['venue'].apply(get_venue_id)\n",
    "print(frequent_venues)\n",
    "train_data['venue_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c8238b",
   "metadata": {},
   "source": [
    "## Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "e77576c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCleanedText(text):\n",
    "    text = text.lower()\n",
    "    tokens=tokenizer.tokenize(text)\n",
    "    new_tokens=[token for token in tokens if token not in en_stop]\n",
    "    stemmed_tokens=[ps.stem(tokens) for tokens in new_tokens]\n",
    "    clean_text=\" \".join(stemmed_tokens)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "b0e2c141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    declin coal start start natur ga took start be...\n",
       "1    hillari clinton agre john mccain vote give geo...\n",
       "2    health care reform legisl like mandat free sex...\n",
       "3                     econom turnaround start end term\n",
       "4    chicago bear start quarterback last 10 year to...\n",
       "Name: statement, dtype: object"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['statement']=train_data['statement'].apply(getCleanedText)\n",
    "train_data['statement'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "14d4f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "f335ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "cf41f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Subjectivity'] = train_data['statement'].apply(getSubjectivity)\n",
    "train_data['Polarity'] = train_data['statement'].apply(getPolarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "82a488e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_statement_vocab_dict(train_data):\n",
    "#     vocabulary_dict = {}\n",
    "#     if not os.path.exists('vocabulary.p'):\n",
    "#         tokenizer = Tokenizer()\n",
    "#         tokenizer.fit_on_texts(train_data['statement'])\n",
    "#         vocabulary_dict = tokenizer.word_index\n",
    "#         print(len(vocabulary_dict))\n",
    "#         pickle.dump(vocabulary_dict, open( \"vocabulary.p\", \"wb\" ))\n",
    "#         print('Created Vocabulary Dictionary...')\n",
    "#         print('Saved Vocabulary Dictionary...')\n",
    "#     else:\n",
    "#         print('Loading Vocabulary Dictionary...')\n",
    "#         vocabulary_dict = pickle.load(open(\"vocabulary.p\", \"rb\" ))\n",
    "#     return vocabulary_dict\n",
    "\n",
    "\n",
    "# def preprocess_statement(statement):\n",
    "#     statement = [w for w in statement.split(' ') if w not in stopwords.words('english')]\n",
    "#     statement = ' '.join(statement)\n",
    "#     text = text_to_word_sequence(statement)\n",
    "#     val = [0] * 10\n",
    "#     val = [vocabulary_dict[t] for t in text if t in vocabulary_dict] \n",
    "#     return val\n",
    "\n",
    "\n",
    "# vocabulary_dict = load_statement_vocab_dict(train_data)\n",
    "# train_data['word_id'] = train_data['statement'].apply(preprocess_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "a67f4aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# # nlp = spacy.load('en')\n",
    "# nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "a278f3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "ac78af8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>job</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>barely-true</th>\n",
       "      <th>false</th>\n",
       "      <th>...</th>\n",
       "      <th>venue</th>\n",
       "      <th>output</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>job_id</th>\n",
       "      <th>party_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>venue_id</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>declin coal start start natur ga took start be...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>state delegate</td>\n",
       "      <td>virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>a floor speech.</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>hillari clinton agre john mccain vote give geo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>president</td>\n",
       "      <td>illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>denver</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>health care reform legisl like mandat free sex...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>none</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>a news release</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>econom turnaround start end term</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>nan</td>\n",
       "      <td>florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>an interview on cnn</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12465.json</td>\n",
       "      <td>true</td>\n",
       "      <td>chicago bear start quarterback last 10 year to...</td>\n",
       "      <td>education</td>\n",
       "      <td>robin-vos</td>\n",
       "      <td>wisconsin assembly speaker</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>republican</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>a an online opinion-piece</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.294444</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        label                                          statement  \\\n",
       "0  10540.json    half-true  declin coal start start natur ga took start be...   \n",
       "1    324.json  mostly-true  hillari clinton agre john mccain vote give geo...   \n",
       "2   1123.json        false  health care reform legisl like mandat free sex...   \n",
       "3   9028.json    half-true                   econom turnaround start end term   \n",
       "4  12465.json         true  chicago bear start quarterback last 10 year to...   \n",
       "\n",
       "                              subject         speaker  \\\n",
       "0  energy,history,job-accomplishments  scott-surovell   \n",
       "1                      foreign-policy    barack-obama   \n",
       "2                         health-care    blog-posting   \n",
       "3                        economy,jobs   charlie-crist   \n",
       "4                           education       robin-vos   \n",
       "\n",
       "                          job      state       party barely-true false  ...  \\\n",
       "0              state delegate   virginia    democrat           0     0  ...   \n",
       "1                   president   illinois    democrat          70    71  ...   \n",
       "2                         nan        nan        none           7    19  ...   \n",
       "3                         nan    florida    democrat          15     9  ...   \n",
       "4  wisconsin assembly speaker  wisconsin  republican           0     3  ...   \n",
       "\n",
       "                       venue output speaker_id job_id  party_id  state_id  \\\n",
       "0            a floor speech.      3         17     12         1         8   \n",
       "1                     denver      4          0      1         1         5   \n",
       "2             a news release      1         13     12         2        16   \n",
       "3        an interview on cnn      3         14     12         1         2   \n",
       "4  a an online opinion-piece      5         17      9         0         3   \n",
       "\n",
       "   subject_id  venue_id  Subjectivity  Polarity  \n",
       "0           8         3      0.000000       0.0  \n",
       "1           6        13      0.000000       0.0  \n",
       "2           0         0      0.800000       0.4  \n",
       "3           6         1      0.000000       0.0  \n",
       "4           4        13      0.294444       0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "19dd9367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'label', 'statement', 'subject', 'speaker', 'job', 'state',\n",
      "       'party', 'barely-true', 'false', 'half-true', 'mostly-true',\n",
      "       'pants-fire', 'venue', 'output', 'speaker_id', 'job_id', 'party_id',\n",
      "       'state_id', 'subject_id', 'venue_id', 'Subjectivity', 'Polarity'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10268, 23)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.columns)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "6821c1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>job_id</th>\n",
       "      <th>party_id</th>\n",
       "      <th>barely-true</th>\n",
       "      <th>false</th>\n",
       "      <th>half-true</th>\n",
       "      <th>mostly-true</th>\n",
       "      <th>pants-fire</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>venue_id</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.294444</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   output  speaker_id  job_id  party_id barely-true false half-true  \\\n",
       "0       3          17      12         1           0     0         1   \n",
       "1       4           0       1         1          70    71       160   \n",
       "2       1          13      12         2           7    19         3   \n",
       "3       3          14      12         1          15     9        20   \n",
       "4       5          17       9         0           0     3         2   \n",
       "\n",
       "  mostly-true pants-fire  state_id  subject_id  venue_id  Subjectivity  \\\n",
       "0           1          0         8           8         3      0.000000   \n",
       "1         163          9         5           6        13      0.000000   \n",
       "2           5         44        16           0         0      0.800000   \n",
       "3          19          2         2           6         1      0.000000   \n",
       "4           5          1         3           4        13      0.294444   \n",
       "\n",
       "   Polarity  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.4  \n",
       "3       0.0  \n",
       "4       0.0  "
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['output', 'speaker_id', 'job_id', 'party_id', 'barely-true', 'false', 'half-true', 'mostly-true', \n",
    "            'pants-fire', 'state_id', 'subject_id', 'venue_id', 'Subjectivity', 'Polarity']\n",
    "\n",
    "data = train_data[features]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "141b0d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10268 entries, 0 to 10267\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   output        10268 non-null  int64  \n",
      " 1   speaker_id    10268 non-null  int64  \n",
      " 2   job_id        10268 non-null  int64  \n",
      " 3   party_id      10268 non-null  int64  \n",
      " 4   barely-true   10268 non-null  object \n",
      " 5   false         10268 non-null  object \n",
      " 6   half-true     10268 non-null  object \n",
      " 7   mostly-true   10268 non-null  object \n",
      " 8   pants-fire    10268 non-null  object \n",
      " 9   state_id      10268 non-null  int64  \n",
      " 10  subject_id    10268 non-null  int64  \n",
      " 11  venue_id      10268 non-null  int64  \n",
      " 12  Subjectivity  10268 non-null  float64\n",
      " 13  Polarity      10268 non-null  float64\n",
      "dtypes: float64(2), int64(7), object(5)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "91064fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('output', axis=1)\n",
    "y = data.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "d152ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "9f8da684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8214, 13), (2054, 13), (8214,), (2054,))"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "a82cb618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "4c4aff8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3018500486854917"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "a9534372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "0ea8bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "8e833ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "cc504a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10268, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "b6febf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5]\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(unique(y))\n",
    "print(unique(y).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "6e0ff6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "39015812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 12, 64)            192       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 12, 16)            1040      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 291       \n",
      "=================================================================\n",
      "Total params: 1,523\n",
      "Trainable params: 1,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 2, activation=\"relu\", input_shape=(13,1)))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', \n",
    "     optimizer = \"adam\",               \n",
    "              metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "5410abbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-359-3a7754ab6cea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loss:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1132\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1134\u001b[1;33m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[0;32m   1135\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1383\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1139\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m                **kwargs):\n\u001b[0;32m    229\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[0;32m    232\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0m_is_scipy_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m   \"\"\"\n\u001b[1;32m-> 1430\u001b[1;33m   return convert_to_tensor_v2(\n\u001b[0m\u001b[0;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0;32m   1432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1434\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   \u001b[1;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1436\u001b[1;33m   return convert_to_tensor(\n\u001b[0m\u001b[0;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1566\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m--> 271\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m   \u001b[1;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=16,epochs=100, verbose=0)\n",
    "\n",
    "acc = model.evaluate(X_train, y_train)\n",
    "print(\"Loss:\", acc[0], \" Accuracy:\", acc[1])\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred_y = pred.argmax(axis=-1)\n",
    "\n",
    "cm = confusion_matrix(y_test, pred_y)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
